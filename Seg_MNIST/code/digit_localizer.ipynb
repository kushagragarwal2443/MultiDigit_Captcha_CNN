{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset sizes: (30000, 40, 168) (30000,)\n",
      "Reformed dataset sizes: (30000, 40, 168, 1) (30000,)\n"
     ]
    }
   ],
   "source": [
    "data_0 = np.load(\"Data/data0.npy\")\n",
    "data_1 = np.load(\"Data/data1.npy\")\n",
    "data_2 = np.load(\"Data/data2.npy\")\n",
    "\n",
    "label_0 = np.load(\"Label/lab0.npy\")\n",
    "label_1 = np.load(\"Label/lab1.npy\")\n",
    "label_2 = np.load(\"Label/lab2.npy\")\n",
    "\n",
    "train_data = np.vstack((data_0, data_1, data_2))\n",
    "train_lab = np.hstack((label_0, label_1, label_2))\n",
    "print(\"Original dataset sizes:\", train_data.shape, train_lab.shape)\n",
    "\n",
    "img_rows = train_data.shape[1]\n",
    "img_cols = train_data.shape[2]\n",
    "\n",
    "train_data = train_data.reshape(-1, img_rows, img_cols, 1)\n",
    "train_data = train_data.reshape(-1, img_rows, img_cols, 1)\n",
    "\n",
    "print(\"Reformed dataset sizes:\", train_data.shape, train_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (i,image) in enumerate(train_data):\n",
    "    \n",
    "#     im = Image.fromarray(image)\n",
    "#     im.save(\"./Converted_images/\" +str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "3 48\n",
      "5 72\n",
      "{'3': [25, 1283, 2199, 3235, 3965, 4110, 4309, 4762, 4782, 5823, 6211, 6625, 7151, 7214, 8145, 9000, 9644, 9854, 10095, 11353, 11439, 11950, 13874, 14919, 15216, 15598, 16135, 16570, 16957, 17296, 17306, 19091, 19175, 19683, 20045, 20539, 20619, 24026, 24413, 24762, 25360, 25382, 28145, 28304, 28910, 29142, 29454, 29564], '5': [245, 1100, 1848, 1943, 2043, 2733, 3615, 3699, 3744, 4741, 4804, 4828, 5060, 5725, 6134, 7344, 8031, 8906, 9261, 9599, 9971, 10365, 10378, 10699, 11192, 11291, 11772, 11865, 12254, 13332, 13714, 14027, 14832, 14950, 15519, 15720, 16034, 16084, 17180, 17357, 17511, 17582, 18814, 19050, 20959, 21197, 21668, 22141, 22302, 22550, 23017, 23483, 23497, 23707, 24678, 24726, 25283, 25413, 26098, 26137, 26333, 26547, 26788, 27015, 27049, 27087, 27149, 27735, 27927, 28939, 29553, 29819]}\n"
     ]
    }
   ],
   "source": [
    "bad_image_count = 0\n",
    "bad_image_dict = dict()\n",
    "for (i,image) in enumerate(train_data):\n",
    "    \n",
    "    padded_image = cv2.copyMakeBorder(image, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
    "#     plt.imshow(padded_image)\n",
    "#     plt.show()\n",
    "    \n",
    "    # find the contours in the image\n",
    "    contours = cv2.findContours(padded_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[1] if imutils.is_cv3() else contours[0]\n",
    "    \n",
    "    letter_image_regions = []\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "#         print(x,y,w,h)\n",
    "\n",
    "        if (w > 40):\n",
    "            # print(\"Splitting into 3\")\n",
    "            # This contour is too wide to be a single letter, hence split\n",
    "            onethird_width = int(w / 3)\n",
    "            letter_image_regions.append((x, y, onethird_width, h))\n",
    "            letter_image_regions.append((x + onethird_width, y, onethird_width, h))\n",
    "            letter_image_regions.append((x + 2*onethird_width, y, onethird_width, h))\n",
    "        \n",
    "        elif (w > 20):\n",
    "            # print(\"Splitting into 2\")\n",
    "            # This contour is too wide to be a single letter, hence split\n",
    "            half_width = int(w / 2)\n",
    "            letter_image_regions.append((x, y, half_width, h))\n",
    "            letter_image_regions.append((x + half_width, y, half_width, h))\n",
    "        \n",
    "        elif(w < 3 or h<9):\n",
    "            # print(\"Error\")\n",
    "            # Some error in contouring, ignore!\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            letter_image_regions.append((x, y, w, h))\n",
    "        \n",
    "    # If more than 4 contours then skip the image instead of saving bad training data!\n",
    "    if len(letter_image_regions) != 4:\n",
    "        \n",
    "        bad_image_count+=1\n",
    "        \n",
    "        if(str(len(letter_image_regions)) not in bad_image_dict):\n",
    "            bad_image_dict[str(len(letter_image_regions))] = [i]\n",
    "            \n",
    "        else:\n",
    "            bad_image_dict[str(len(letter_image_regions))].append(i)\n",
    "\n",
    "        continue\n",
    "\n",
    "    # Sort the detected letter images based on the x coordinate\n",
    "    letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])\n",
    "    \n",
    "    # Save out each letter as a single image\n",
    "    for letter_bounding_box in letter_image_regions:\n",
    "    \n",
    "        x, y, w, h = letter_bounding_box\n",
    "\n",
    "        letter_image = padded_image[y-2:y + h+2, x-2:x + w+2]\n",
    "#         plt.imshow(letter_image)\n",
    "#         plt.show()\n",
    "\n",
    "print(bad_image_count)\n",
    "for key in bad_image_dict:\n",
    "    print(key,len(bad_image_dict[key]))    \n",
    "print(bad_image_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
